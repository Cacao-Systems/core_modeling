{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard lib imports\n",
    "from functools import partial\n",
    "from os.path import join as join_path, abspath\n",
    "from sys import path as sys_path\n",
    "from typing import Optional\n",
    "\n",
    "# Numeric libraries\n",
    "from matplotlib.pyplot import figure\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.optim.sgd import SGD\n",
    "from sklearn.datasets import make_moons\n",
    "\n",
    "# inhouse imports\n",
    "    # enabling imports of \"adjacent\" modules\n",
    "module_path = abspath(join_path(\"..\"))\n",
    "if module_path not in sys_path:\n",
    "    sys_path.append(module_path)\n",
    "\n",
    "from lib.definitions import meta_ds, meta_sample, modeling_ds\n",
    "from lib.learning_utils import collate_modeling_samples\n",
    "from lib.nn_blocks import fc_classifier\n",
    "from lib.nn_optimize import train, validate\n",
    "from lib.learning_metrics import md_classification_accuracy\n",
    "\n",
    "\n",
    "#region Visualization \n",
    "from bokeh.plotting import figure as bokeh_figure, output_notebook, show, ColumnDataSource\n",
    "from bokeh.io.notebook import push_notebook \n",
    "from bokeh.layouts import column\n",
    "output_notebook()\n",
    "#endregion "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "N_TRAIN, N_VALID = 300, 100 \n",
    "assert N_TRAIN != N_VALID, \"You will get identical sampling for training and validation\"\n",
    "NOISE = 0.15\n",
    "SEED = 5\n",
    "\n",
    "# Optimization\n",
    "BATCH_SZ = 8\n",
    "EPOCH_CNT = 1000\n",
    "\n",
    "# Model\n",
    "LINEAR_BLOCKS_DIMS = [16, 16]\n",
    "LINEAR_BLOCKS_ACTIVATIONS = ['relu', 'relu', 'sigmoid']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = make_moons(n_samples = N_TRAIN,\n",
    "                noise = NOISE,\n",
    "                random_state = SEED)\n",
    "\n",
    "x_valid, y_valid = make_moons(n_samples = N_VALID,\n",
    "                noise = NOISE,\n",
    "                random_state = SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "train_one_indices = np.argwhere(y_train == 1)\n",
    "train_zero_indices = np.argwhere(y_train == 0)\n",
    "ax.plot(x_train[train_one_indices, 0], x_train[train_one_indices, 1], \"k.\");\n",
    "ax.plot(x_train[train_zero_indices, 0], x_train[train_zero_indices, 1], \"r.\");\n",
    "valid_one_indices = np.argwhere(y_valid == 1)\n",
    "valid_zero_indices = np.argwhere(y_valid == 0)\n",
    "ax.plot(x_valid[valid_one_indices, 0], x_valid[valid_one_indices, 1], \"kx\",\\\n",
    "        markersize = 10);\n",
    "ax.plot(x_valid[valid_zero_indices, 0], x_valid[valid_zero_indices, 1], \"rx\",\\\n",
    "        markersize = 10);\n",
    "ax.legend([\"Training Data Upper\", \"Training Data Lower\",\\\n",
    "            \"Validation Data Upper\", \"Training Data Lower\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Meta-data datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class moon_sample(meta_sample):\n",
    "    def __init__(self, idx, ds_identity):\n",
    "        super().__init__(f\"{idx}_{ds_identity}\")\n",
    "        self.idx = idx\n",
    "    def __repr__(self) -> str:\n",
    "        return self.identity\n",
    "\n",
    "class moon_meta_ds(meta_ds):\n",
    "    def __init__(self, samples_cnt, noise, seed):\n",
    "        self.ds_identity = \\\n",
    "        f\"noise_{noise}_N_{samples_cnt}_seed_{seed}\"\n",
    "        self.samples_cnt = samples_cnt\n",
    "    def __len__(self):\n",
    "        return self.samples_cnt\n",
    "\n",
    "    def __getitem__(self, ind: int) -> meta_sample:\n",
    "        if ind >= self.samples_cnt:\n",
    "            raise IndexError(\n",
    "                f\"The dataset only has {self.samples_cnt} samples.\")\n",
    "        return moon_sample(ind, self.ds_identity)\n",
    "\n",
    "train_meta_ds = moon_meta_ds(samples_cnt = N_TRAIN,\n",
    "                             noise = NOISE,\n",
    "                             seed = SEED)\n",
    "\n",
    "valid_meta_ds = moon_meta_ds(samples_cnt = N_VALID,\n",
    "                            noise = NOISE,\n",
    "                            seed = SEED)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create modeling dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def x_creator(data_x : np.ndarray, sample : moon_sample):\n",
    "    return torch.tensor(data_x[sample.idx, : ]).reshape(shape = [1, 2])\n",
    "\n",
    "def y_creator(data_y : np.ndarray, sample : moon_sample):\n",
    "    return torch.tensor(data_y[sample.idx]).reshape(shape = [1, 1])\n",
    "\n",
    "train_model_ds = modeling_ds(\n",
    "    meta_ds = train_meta_ds,\n",
    "    x_creator = partial(x_creator, x_train),\n",
    "    y_creator = partial(y_creator, y_train))\n",
    "\n",
    "valid_model_ds = modeling_ds(\n",
    "    meta_ds = valid_meta_ds,\n",
    "    x_creator = partial(x_creator, x_valid),\n",
    "    y_creator = partial(y_creator, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Batchers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batcher_train = DataLoader(dataset = train_model_ds,\n",
    "                           batch_size = BATCH_SZ,\n",
    "                           collate_fn = collate_modeling_samples)\n",
    "\n",
    "batcher_valid = DataLoader(dataset = valid_model_ds,\n",
    "                           batch_size = BATCH_SZ,\n",
    "                           collate_fn = collate_modeling_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = fc_classifier(input_dim = 2,\n",
    "                        output_dim = 2,\n",
    "                        linear_block_sizes = LINEAR_BLOCKS_DIMS,\n",
    "                        linear_block_activations = LINEAR_BLOCKS_ACTIVATIONS)\n",
    "    return model\n",
    "model = create_model()\n",
    "model = model.to(torch.float64)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Optimizer and loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = SGD(model.parameters(), lr = 0.1)\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "def metric (y_hat, y):\n",
    "    return  md_classification_accuracy(y_hat, y), y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = model(next(iter(batcher_train))[0])\n",
    "y = next(iter(batcher_train))[1]\n",
    "metric(y_hat, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_ds = ColumnDataSource({'epoch':[], 'train_accu':[], 'valid_accu':[]})\n",
    "accu_fig = bokeh_figure(width=1200, height=400, tools='hover,box_zoom,reset')\n",
    "accu_fig.line(x='epoch', y='train_accu', source=training_ds, line_color='black', legend_label='Training Accuracy')\n",
    "accu_fig.line(x='epoch', y='valid_accu', source=training_ds, line_color='red', legend_label='Validation Accuracy')\n",
    "accu_fig.xaxis.axis_label = 'epoch'\n",
    "accu_fig.yaxis.axis_label = 'accuracy'\n",
    "accu_fig.legend.location = \"top_left\"\n",
    "accu_fig.legend.click_policy = \"hide\"\n",
    "\n",
    "show(accu_fig, notebook_handle = True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch_i in range(EPOCH_CNT):\n",
    "    train_avg_accu, train_avg_loss = train(\n",
    "        train_loader = batcher_train,\n",
    "        model = model,\n",
    "        criterion = loss,\n",
    "        metric_func = metric,\n",
    "        optimizer = optimizer,\n",
    "        epoch = epoch_i)\n",
    "    \n",
    "    valid_avg_accu, valid_avg_loss = validate(batcher_valid,\n",
    "            model,\n",
    "            loss,\n",
    "            metric,\n",
    "            epoch_i,\n",
    "            print_fn = print)\n",
    "\n",
    "    new_data = {'epoch':[epoch_i],\n",
    "                'train_accu':[train_avg_accu],\n",
    "                'valid_accu':[valid_avg_accu]}\n",
    "    training_ds.stream(new_data)\n",
    "    push_notebook()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
